{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import urllib3\n",
    "import csv\n",
    "import logging\n",
    "import re\n",
    "import uuid\n",
    "import shortuuid\n",
    "from pathlib import Path\n",
    "from idmc_utils import generate_taskflow, package_import\n",
    "from urllib.parse import quote\n",
    "\n",
    "# Set the pandas options\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the log file\n",
    "logging.basicConfig(\n",
    "    filename='logs/console.log',\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s:%(levelname)s:%(message)s',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the config file\n",
    "logging.info('Reading the config file')\n",
    "with open('config/config.json', 'r') as infile:\n",
    "    config = json.load(infile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the execution plans\n",
    "logging.info('Reading the execution plans')\n",
    "dfPlans = pd.read_csv('in/plans.csv', dtype='str', encoding='utf-8', na_filter=False)\n",
    "dfPlans['plan_step_order'] = dfPlans['plan_step_order'].astype(int)\n",
    "\n",
    "#TODO remove the below filter once done with testing\n",
    "test_plans = [\n",
    "    'Echo Employee Snapshot Oracle R12.1.3', \n",
    "    'Echo GL Balance Refresh', \n",
    "    'Echo Account Dimension', \n",
    "    'Human Resources - Oracle R1213 - Flexfield', \n",
    "    'Common-LoadDayDimension Universal',\n",
    "    'Process_Quality_OracleR1213'\n",
    "    ]\n",
    "dfPlans = dfPlans[dfPlans['plan_name'].isin(test_plans)]\n",
    "\n",
    "# Read the parameter files\n",
    "dfParams = pd.read_csv('in/params.csv', dtype='str', encoding='utf-8', na_filter=False)\n",
    "dfParams = dfParams.merge(dfPlans, how='inner', on='step_wid')\n",
    "dfParams = dfParams[['name', 'value', 'type_cd', 'step_wid', 'datatype', 'context_type',\n",
    "       'inactive_flag', 'comments', 'plan_name', 'step_name']]\n",
    "dfParams = dfParams.drop_duplicates()\n",
    "dfParams['param_filename'] = dfParams['plan_name'].apply(lambda x: re.sub(r'\\W+', '_', x) + '.param')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lookup the Converted Mapping Task IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to IDMC\n",
    "logging.info('Logging into IDMC')\n",
    "http = urllib3.PoolManager()\n",
    "\n",
    "data = '{ \"username\": \"' + config['idmc']['user'] + '\", \"password\": \"' + config['idmc']['password'] + '\" }'\n",
    "\n",
    "url = 'https://' + config['idmc']['host'] + '/saas/public/core/v3/login'\n",
    "r = http.request(\n",
    "    'POST', \n",
    "    url,\n",
    "    timeout=3000,\n",
    "    body=data,\n",
    "    headers={\n",
    "            'Accept': 'application/json',\n",
    "            'Content-Type': 'application/json'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "# Convert the response into a datframe\n",
    "result = json.loads(r.data.decode('utf-8'))\n",
    "sessionID = result['userInfo']['sessionId']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the secure agent ID\n",
    "logging.info('Getting the secure agent ID')\n",
    "url = 'https://' + config['idmc']['pod'] + '.' + config['idmc']['host'] + '/saas/api/v2/runtimeEnvironment/name/' + quote(config['idmc']['agentGroupName'])\n",
    "r = http.request(\n",
    "    'GET', \n",
    "    url,\n",
    "    timeout=3000,\n",
    "    headers={\n",
    "            'Accept': 'application/json',\n",
    "            'icSessionId': sessionID\n",
    "        }\n",
    "    )\n",
    "    \n",
    "# Convert the response into a datframe\n",
    "result = json.loads(r.data.decode('utf-8'))\n",
    "agentGroupID = result['id']\n",
    "agentGroupGUID = result['federatedId']\n",
    "agentGroupName = config['idmc']['agentGroupName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looping. dfCount = 200; i = 200; taskCount = 299\n",
      "Finished. dfCount = 299; i = 400; taskCount = 299\n"
     ]
    }
   ],
   "source": [
    "# Initialise the tasks data frame\n",
    "logging.info('Getting a list of the mapping tasks')\n",
    "limit = 200\n",
    "i = 0\n",
    "dfTasks = pd.DataFrame()\n",
    "\n",
    "# Page through mapping task queries\n",
    "while True:\n",
    "\n",
    "    # Get a list of the mapping tasks\n",
    "    url = 'https://' + config['idmc']['pod'] + '.' + config['idmc']['host'] + '/saas/public/core/v3/objects?q=type==%27MTT%27&limit=' + str(limit) + '&skip=' + str(i)\n",
    "    r = http.request(\n",
    "        'GET', \n",
    "        url,\n",
    "        timeout=3000,\n",
    "        headers={\n",
    "                'Accept': 'application/json',\n",
    "                'INFA-SESSION-ID': sessionID\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    # Convert the response into a datframe\n",
    "    result = json.loads(r.data.decode('utf-8'))\n",
    "    dfTmp = pd.json_normalize(result)\n",
    "    dfResp = dfTmp.copy()\n",
    "    taskCount = dfResp.iloc[0]['count']\n",
    "    dfResp = dfResp['objects'].explode()\n",
    "    dfResp = pd.DataFrame(dfResp)\n",
    "    dfResp = pd.json_normalize(dfResp['objects'])\n",
    "    dfTasks = pd.concat([dfTasks, dfResp], ignore_index=True)\n",
    "\n",
    "    # Break if all records have been returned\n",
    "    i = i + limit\n",
    "    if i > taskCount:\n",
    "        print(f'Finished. dfCount = { len(dfTasks) }; i = { i }; taskCount = { taskCount }')\n",
    "        break\n",
    "\n",
    "    print(f'Looping. dfCount = { len(dfTasks) }; i = { i }; taskCount = { taskCount }')\n",
    "\n",
    "# Clean up the list of returned tasks\n",
    "dfTasks = dfTasks.drop(columns=['tags'])\n",
    "dfTasks = dfTasks.drop_duplicates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the IDMC info onto the plans\n",
    "dfTasks['step_name'] = dfTasks['path'].apply(lambda x: os.path.basename(x))\n",
    "dfTasks = dfTasks[['step_name','id','path']]\n",
    "dfTasks = dfTasks.rename(columns={'id': 'infa_id', 'path': 'infa_path'})\n",
    "dfPlans = dfPlans.merge(dfTasks, how='left', on='step_name')\n",
    "dfPlans['agent_id'] = agentGroupID\n",
    "dfPlans['agent_guid'] = agentGroupGUID\n",
    "dfPlans['agent_name'] = agentGroupName\n",
    "dfPlans['script_dir'] = config['local']['scriptsDir']\n",
    "dfPlans['script_args'] = '' # TODO placeholder for any args that need to be passed to the step script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log an error if any plans did not find an existing matching task\n",
    "dfMissing = dfPlans[(dfPlans['infa_id'] == '') | (dfPlans['infa_id'].isna())].copy()\n",
    "if len(dfMissing.index) > 0:\n",
    "    logging.error('Some plans are missing a converted mapping task. Please see \"out/missing_tasks.csv\" for more details')\n",
    "    dfMissing.to_csv('out/missing_tasks.csv', index=False, quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the Parameter Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('Generating the parameter files...')\n",
    "unique_files = dfParams['param_filename'].unique()\n",
    "\n",
    "for filename in unique_files:\n",
    "    \n",
    "    logging.info(f'Generating the parameter file \"out/{ filename }\"...')\n",
    "    unique_sections = dfParams[dfParams['param_filename'] == filename]['step_name'].unique()\n",
    "\n",
    "    # Set the param file header\n",
    "    lines = ['#USE_SECTIONS', '']\n",
    "\n",
    "    for section in unique_sections:\n",
    "\n",
    "        dfSection = dfParams[( dfParams['param_filename'] == filename ) & ( dfParams['step_name'] == section )].copy()\n",
    "\n",
    "        # Append the section header\n",
    "        step_name = dfSection.iloc[0][\"step_name\"]\n",
    "        lines.append(f'[Default].[{ step_name }]')\n",
    "\n",
    "        # Add the parameter values\n",
    "        for idx, row  in dfSection.iterrows():\n",
    "            param_name = row['name']\n",
    "            param_value = row['value']\n",
    "            lines.append(f\"{ param_name }={ param_value }\")\n",
    "        lines.append('')\n",
    "\n",
    "    # Add the global footer\n",
    "    lines.append('[Global]')\n",
    "    lines.append('')\n",
    "\n",
    "    with open(f'out/{ filename }', 'w', encoding='utf-8') as file:\n",
    "        file.write('\\n'.join(lines))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the Taskflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D3CA457A65BED1FA6E627DF045DFC5A1\n",
      "74CB216C9DA89FAC19D2A05895E89F74\n",
      "201C9CC7C59D167A79A2E247C6189A67\n",
      "4C7EB9C8BB06489745D4C93191C1EF0\n",
      "88898EF341B9D0DF4C39965380BD566\n",
      "D1EE996AB7E780BDB2FDC9BCEDB3CB4C\n"
     ]
    }
   ],
   "source": [
    "logging.info('Generating the taskflows...')\n",
    "planIds = dfPlans['plan_wid'].unique()\n",
    "\n",
    "for planId in planIds:\n",
    "\n",
    "    # Get the plan for the current id\n",
    "    dfPlan = dfPlans[dfPlans['plan_wid'] == planId].copy()\n",
    "\n",
    "    # Generate the unique identifiers\n",
    "    dfPlan['dac2idmc_step_id'] = dfPlan.apply(lambda x: \"task\" + shortuuid.uuid()[:8], axis=1)\n",
    "    map_order_uuid = { step_order: \"group\" + shortuuid.uuid()[:8] for step_order in dfPlan['plan_step_order'].unique() }\n",
    "    dfPlan = dfPlan.sort_values(['plan_wid', 'plan_step_order', 'step_name'])\n",
    "    dfPlan['sequence'] = range(len(dfPlan))\n",
    "    dfPlan['dac2idmc_group_id'] = dfPlan['plan_step_order'].map(map_order_uuid)\n",
    "    dfPlan['dac2idmc_next_id'] = dfPlan['dac2idmc_step_id'].shift(-1)\n",
    "\n",
    "    # Get the next group IDs and sort the plans\n",
    "    dfGroups = dfPlan[['plan_step_order','dac2idmc_group_id']].copy()\n",
    "    dfGroups = dfGroups.drop_duplicates()\n",
    "    dfGroups = dfGroups.sort_values(['plan_step_order'])\n",
    "    dfGroups['dac2idmc_next_group'] = dfGroups['dac2idmc_group_id'].shift(-1)\n",
    "    dfGroups = dfGroups[['dac2idmc_group_id','dac2idmc_next_group']]\n",
    "\n",
    "    dfPlan = dfPlan.merge(dfGroups, how='inner', on='dac2idmc_group_id')\n",
    "    dfPlan = dfPlan.sort_values(['sequence'])\n",
    "\n",
    "    #TODO Uncomment the below lines for troubleshooting\n",
    "    #print(planId)\n",
    "    #dfPlan.to_excel(f'out/{ planId }.xlsx')\n",
    "\n",
    "    # Generate the taskflow ID\n",
    "    taskflowID = shortuuid.uuid()\n",
    "    taskflowName = dfPlan.iloc[0]['plan_name']\n",
    "    taskflowName = re.sub(r'\\W+', '_', taskflowName)\n",
    "\n",
    "    logging.info(f'Create workspace tree \"tmp/{ taskflowName }/Explore/Default\"')\n",
    "\n",
    "    # Create the workspace directories\n",
    "    treePath = Path(f'tmp/{ taskflowName }/Explore/Default')\n",
    "    treePath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    logging.info(f'Generating taskflow \"{ taskflowName }\"')\n",
    "    generate_taskflow.generate_taskflow(taskflowID, taskflowName, dfPlan, config)\n",
    "\n",
    "    logging.info(f'Packaging taskflow \"{ taskflowName }\"')\n",
    "    package_import.package_import(taskflowID, taskflowName, dfPlan)\n",
    "\n",
    "    logging.info(f'Done!')\n",
    "\n",
    "logging.info('All taskflows have been generated!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing below this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step_name</th>\n",
       "      <th>infa_id</th>\n",
       "      <th>infa_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Load into Geography Dimension</td>\n",
       "      <td>4o6rpkCrceZiaOCY5g88eY</td>\n",
       "      <td>Default/Load into Geography Dimension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Load into Position Dimension</td>\n",
       "      <td>9ArGrsQE0F6jWzNaGutI0a</td>\n",
       "      <td>Default/Load into Position Dimension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Load into Product Dimension</td>\n",
       "      <td>33MaHQmgquFlHadf7pJM4W</td>\n",
       "      <td>Default/Load into Product Dimension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mp_ext_RAW_Key</td>\n",
       "      <td>an4lj4o3X5HdQ7dxzJ94eP</td>\n",
       "      <td>Customers/Bunnings/mp_ext_RAW_Key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mp_Simultaneous</td>\n",
       "      <td>7mSYo2bLKJwkBtbvHiV3ua</td>\n",
       "      <td>Default/mp_Simultaneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>TASK_GROUP_Load_PositionDimension</td>\n",
       "      <td>2V63mNQ1pKOhPGebjdsBw0</td>\n",
       "      <td>Default/TASK_GROUP_Load_PositionDimension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>TASK_GROUP_Load_PositionHierarchy</td>\n",
       "      <td>3mW2lCshevukLlOW2OfTMQ</td>\n",
       "      <td>Default/TASK_GROUP_Load_PositionHierarchy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>TASK_GROUP_Pre_Load_Positionhierarchy</td>\n",
       "      <td>1FGrllzaPSDdLjiBYziuAL</td>\n",
       "      <td>Default/TASK_GROUP_Pre_Load_Positionhierarchy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>TC_ValueTest_NoSample__MCT__1692288033153</td>\n",
       "      <td>iBQsmsvfrcWd1gixaRh0Ur</td>\n",
       "      <td>Default/TC_ValueTest_NoSample__MCT__1692288033153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Update Parameters</td>\n",
       "      <td>8W48szhy8DSdq0P4SslDI5</td>\n",
       "      <td>Default/Update Parameters</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     step_name                 infa_id  \\\n",
       "0                Load into Geography Dimension  4o6rpkCrceZiaOCY5g88eY   \n",
       "1                 Load into Position Dimension  9ArGrsQE0F6jWzNaGutI0a   \n",
       "2                  Load into Product Dimension  33MaHQmgquFlHadf7pJM4W   \n",
       "3                               mp_ext_RAW_Key  an4lj4o3X5HdQ7dxzJ94eP   \n",
       "4                              mp_Simultaneous  7mSYo2bLKJwkBtbvHiV3ua   \n",
       "..                                         ...                     ...   \n",
       "294          TASK_GROUP_Load_PositionDimension  2V63mNQ1pKOhPGebjdsBw0   \n",
       "295          TASK_GROUP_Load_PositionHierarchy  3mW2lCshevukLlOW2OfTMQ   \n",
       "296      TASK_GROUP_Pre_Load_Positionhierarchy  1FGrllzaPSDdLjiBYziuAL   \n",
       "297  TC_ValueTest_NoSample__MCT__1692288033153  iBQsmsvfrcWd1gixaRh0Ur   \n",
       "298                          Update Parameters  8W48szhy8DSdq0P4SslDI5   \n",
       "\n",
       "                                             infa_path  \n",
       "0                Default/Load into Geography Dimension  \n",
       "1                 Default/Load into Position Dimension  \n",
       "2                  Default/Load into Product Dimension  \n",
       "3                    Customers/Bunnings/mp_ext_RAW_Key  \n",
       "4                              Default/mp_Simultaneous  \n",
       "..                                                 ...  \n",
       "294          Default/TASK_GROUP_Load_PositionDimension  \n",
       "295          Default/TASK_GROUP_Load_PositionHierarchy  \n",
       "296      Default/TASK_GROUP_Pre_Load_Positionhierarchy  \n",
       "297  Default/TC_ValueTest_NoSample__MCT__1692288033153  \n",
       "298                          Default/Update Parameters  \n",
       "\n",
       "[299 rows x 3 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTasks[dfTasks['step_name'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
