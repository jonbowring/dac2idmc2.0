{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import urllib3\n",
    "import csv\n",
    "import logging\n",
    "import re\n",
    "import uuid\n",
    "import shortuuid\n",
    "from pathlib import Path\n",
    "from idmc_utils import generate_taskflow, package_import\n",
    "from urllib.parse import quote\n",
    "\n",
    "# Set the pandas options\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the log file\n",
    "logging.basicConfig(\n",
    "    filename='logs/console.log',\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s:%(levelname)s:%(message)s',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the config file\n",
    "logging.info('Reading the config file')\n",
    "with open('config/config.json', 'r') as infile:\n",
    "    config = json.load(infile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the execution plans\n",
    "logging.info('Reading the execution plans')\n",
    "dfPlans = pd.read_csv('in/plans.csv', dtype='str', encoding='utf-8', na_filter=False)\n",
    "dfPlans['plan_step_order'] = dfPlans['plan_step_order'].astype(int)\n",
    "\n",
    "#TODO remove the below filter once done with testing\n",
    "test_plans = [\n",
    "    'Echo Employee Snapshot Oracle R12.1.3', \n",
    "    'Echo GL Balance Refresh', \n",
    "    'Echo Account Dimension', \n",
    "    'Human Resources - Oracle R1213 - Flexfield', \n",
    "    'Common-LoadDayDimension Universal',\n",
    "    'Process_Quality_OracleR1213'\n",
    "    ]\n",
    "dfPlans = dfPlans[dfPlans['plan_name'].isin(test_plans)]\n",
    "\n",
    "# Read the parameter files\n",
    "dfParams = pd.read_csv('in/params.csv', dtype='str', encoding='utf-8', na_filter=False)\n",
    "dfParams = dfParams.merge(dfPlans, how='inner', on='step_wid')\n",
    "dfParams = dfParams[['name', 'value', 'type_cd', 'step_wid', 'datatype', 'context_type',\n",
    "       'inactive_flag', 'comments', 'plan_name', 'step_name']]\n",
    "dfParams = dfParams.drop_duplicates()\n",
    "dfParams['param_filename'] = dfParams['plan_name'].apply(lambda x: re.sub(r'\\W+', '_', x) + '.param')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lookup the Converted Mapping Task IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to IDMC\n",
    "logging.info('Logging into IDMC')\n",
    "http = urllib3.PoolManager()\n",
    "\n",
    "data = '{ \"username\": \"' + config['idmc']['user'] + '\", \"password\": \"' + config['idmc']['password'] + '\" }'\n",
    "\n",
    "url = 'https://' + config['idmc']['host'] + '/saas/public/core/v3/login'\n",
    "r = http.request(\n",
    "    'POST', \n",
    "    url,\n",
    "    timeout=3000,\n",
    "    body=data,\n",
    "    headers={\n",
    "            'Accept': 'application/json',\n",
    "            'Content-Type': 'application/json'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "# Convert the response into a datframe\n",
    "result = json.loads(r.data.decode('utf-8'))\n",
    "sessionID = result['userInfo']['sessionId']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the secure agent ID\n",
    "logging.info('Getting the secure agent ID')\n",
    "url = 'https://' + config['idmc']['pod'] + '.' + config['idmc']['host'] + '/saas/api/v2/runtimeEnvironment/name/' + quote(config['idmc']['agentGroupName'])\n",
    "r = http.request(\n",
    "    'GET', \n",
    "    url,\n",
    "    timeout=3000,\n",
    "    headers={\n",
    "            'Accept': 'application/json',\n",
    "            'icSessionId': sessionID\n",
    "        }\n",
    "    )\n",
    "    \n",
    "# Convert the response into a datframe\n",
    "result = json.loads(r.data.decode('utf-8'))\n",
    "agentGroupID = result['id']\n",
    "agentGroupGUID = result['federatedId']\n",
    "agentGroupName = config['idmc']['agentGroupName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the tasks data frame\n",
    "logging.info('Getting a list of the mapping tasks')\n",
    "limit = 200\n",
    "i = 0\n",
    "dfTasks = pd.DataFrame()\n",
    "\n",
    "# Page through mapping task queries\n",
    "while True:\n",
    "\n",
    "    # Get a list of the mapping tasks\n",
    "    url = 'https://' + config['idmc']['pod'] + '.' + config['idmc']['host'] + '/saas/public/core/v3/objects?q=type==%27MTT%27&limit=' + str(limit) + '&skip=' + str(i)\n",
    "    r = http.request(\n",
    "        'GET', \n",
    "        url,\n",
    "        timeout=3000,\n",
    "        headers={\n",
    "                'Accept': 'application/json',\n",
    "                'INFA-SESSION-ID': sessionID\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    # Convert the response into a datframe\n",
    "    result = json.loads(r.data.decode('utf-8'))\n",
    "    dfTmp = pd.json_normalize(result)\n",
    "    dfResp = dfTmp.copy()\n",
    "    taskCount = dfResp.iloc[0]['count']\n",
    "    dfResp = dfResp['objects'].explode()\n",
    "    dfResp = pd.DataFrame(dfResp)\n",
    "    dfResp = pd.json_normalize(dfResp['objects'])\n",
    "    dfTasks = pd.concat([dfTasks, dfResp], ignore_index=True)\n",
    "\n",
    "    # Break if all records have been returned\n",
    "    i = i + limit\n",
    "    if i > taskCount:\n",
    "        print(f'Finished. dfCount = { len(dfTasks) }; i = { i }; taskCount = { taskCount }')\n",
    "        break\n",
    "\n",
    "    print(f'Looping. dfCount = { len(dfTasks) }; i = { i }; taskCount = { taskCount }')\n",
    "\n",
    "# Clean up the list of returned tasks\n",
    "dfTasks = dfTasks.drop(columns=['tags'])\n",
    "dfTasks = dfTasks.drop_duplicates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the IDMC info onto the plans\n",
    "dfTasks['step_name'] = dfTasks['path'].apply(lambda x: os.path.basename(x))\n",
    "dfTasks = dfTasks[['step_name','id','path']]\n",
    "dfTasks = dfTasks.rename(columns={'id': 'infa_id', 'path': 'infa_path'})\n",
    "dfPlans = dfPlans.merge(dfTasks, how='left', on='step_name')\n",
    "dfPlans['agent_id'] = agentGroupID\n",
    "dfPlans['agent_guid'] = agentGroupGUID\n",
    "dfPlans['agent_name'] = agentGroupName\n",
    "dfPlans['script_dir'] = config['local']['scriptsDir']\n",
    "dfPlans['script_args'] = '' # TODO placeholder for any args that need to be passed to the step script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log an error if any plans did not find an existing matching task\n",
    "dfMissing = dfPlans[(dfPlans['infa_id'] == '') | (dfPlans['infa_id'].isna())].copy()\n",
    "if len(dfMissing.index) > 0:\n",
    "    logging.error('Some plans are missing a converted mapping task. Please see \"out/missing_tasks.csv\" for more details')\n",
    "    dfMissing.to_csv('out/missing_tasks.csv', index=False, quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the Parameter Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('Generating the parameter files...')\n",
    "unique_files = dfParams['param_filename'].unique()\n",
    "\n",
    "for filename in unique_files:\n",
    "    \n",
    "    logging.info(f'Generating the parameter file \"out/{ filename }\"...')\n",
    "    unique_sections = dfParams[dfParams['param_filename'] == filename]['step_name'].unique()\n",
    "\n",
    "    # Set the param file header\n",
    "    lines = ['#USE_SECTIONS', '']\n",
    "\n",
    "    for section in unique_sections:\n",
    "\n",
    "        dfSection = dfParams[( dfParams['param_filename'] == filename ) & ( dfParams['step_name'] == section )].copy()\n",
    "\n",
    "        # Append the section header\n",
    "        step_name = dfSection.iloc[0][\"step_name\"]\n",
    "        lines.append(f'[Default].[{ step_name }]')\n",
    "\n",
    "        # Add the parameter values\n",
    "        for idx, row  in dfSection.iterrows():\n",
    "            param_name = row['name']\n",
    "            param_value = row['value']\n",
    "            lines.append(f\"{ param_name }={ param_value }\")\n",
    "        lines.append('')\n",
    "\n",
    "    # Add the global footer\n",
    "    lines.append('[Global]')\n",
    "    lines.append('')\n",
    "\n",
    "    with open(f'out/{ filename }', 'w', encoding='utf-8') as file:\n",
    "        file.write('\\n'.join(lines))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the Taskflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('Generating the taskflows...')\n",
    "planIds = dfPlans['plan_wid'].unique()\n",
    "\n",
    "for planId in planIds:\n",
    "\n",
    "    # Get the plan for the current id\n",
    "    dfPlan = dfPlans[dfPlans['plan_wid'] == planId].copy()\n",
    "\n",
    "    # Generate the unique identifiers\n",
    "    dfPlan['dac2idmc_step_id'] = dfPlan.apply(lambda x: \"task\" + shortuuid.uuid()[:8], axis=1)\n",
    "    map_order_uuid = { step_order: \"group\" + shortuuid.uuid()[:8] for step_order in dfPlan['plan_step_order'].unique() }\n",
    "    dfPlan = dfPlan.sort_values(['plan_wid', 'plan_step_order', 'step_name'])\n",
    "    dfPlan['sequence'] = range(len(dfPlan))\n",
    "    dfPlan['dac2idmc_group_id'] = dfPlan['plan_step_order'].map(map_order_uuid)\n",
    "    dfPlan['dac2idmc_next_id'] = dfPlan['dac2idmc_step_id'].shift(-1)\n",
    "\n",
    "    # Get the next group IDs and sort the plans\n",
    "    dfGroups = dfPlan[['plan_step_order','dac2idmc_group_id']].copy()\n",
    "    dfGroups = dfGroups.drop_duplicates()\n",
    "    dfGroups = dfGroups.sort_values(['plan_step_order'])\n",
    "    dfGroups['dac2idmc_next_group'] = dfGroups['dac2idmc_group_id'].shift(-1)\n",
    "    dfGroups = dfGroups[['dac2idmc_group_id','dac2idmc_next_group']]\n",
    "\n",
    "    dfPlan = dfPlan.merge(dfGroups, how='inner', on='dac2idmc_group_id')\n",
    "    dfPlan = dfPlan.sort_values(['sequence'])\n",
    "\n",
    "    #TODO Uncomment the below lines for troubleshooting\n",
    "    #print(planId)\n",
    "    #dfPlan.to_excel(f'out/{ planId }.xlsx')\n",
    "\n",
    "    # Generate the taskflow ID\n",
    "    taskflowID = shortuuid.uuid()\n",
    "    taskflowName = dfPlan.iloc[0]['plan_name']\n",
    "    taskflowName = re.sub(r'\\W+', '_', taskflowName)\n",
    "\n",
    "    logging.info(f'Create workspace tree \"tmp/{ taskflowName }/Explore/Default\"')\n",
    "\n",
    "    # Create the workspace directories\n",
    "    treePath = Path(f'tmp/{ taskflowName }/Explore/Default')\n",
    "    treePath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    logging.info(f'Generating taskflow \"{ taskflowName }\"')\n",
    "    generate_taskflow.generate_taskflow(taskflowID, taskflowName, dfPlan, config)\n",
    "\n",
    "    logging.info(f'Packaging taskflow \"{ taskflowName }\"')\n",
    "    package_import.package_import(taskflowID, taskflowName, dfPlan)\n",
    "\n",
    "    logging.info(f'Done!')\n",
    "\n",
    "logging.info('All taskflows have been generated!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing below this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTasks[dfTasks['step_name'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
